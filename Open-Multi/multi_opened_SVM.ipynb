{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rHrbvaVhkyn7",
    "outputId": "31fc182c-140f-42d9-bb34-1b9be8772827"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import pandas as pd\n",
    "unmon_features= pd.read_csv('/content/drive/MyDrive/MLproject/unmon_features.csv')\n",
    "mon_features= pd.read_csv('/content/drive/MyDrive/MLproject/mon_features.csv')\n",
    "mon_labels = pd.read_csv('/content/drive/MyDrive/MLproject/mon_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tVjfxoFq9Ns-",
    "outputId": "f7a4469a-e9dc-40bf-c815-9a53942246fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Data Shape: (29000, 20)\n",
      "Feature Matrix Shape (X): (29000, 19)\n",
      "<bound method NDFrame.head of       total_num  total_sum_dir  total_avg  inpkt_num  inpkt_avg  inpkt_sum  \\\n",
      "0         19000        -603648   4.315749       1300   4.292023    5579.63   \n",
      "1         19000        -183296   4.611815        438   4.673242    2046.88   \n",
      "2         19000        -574464   5.488969       1240   5.459452    6769.72   \n",
      "3         19000        -615424   5.995512       1324   5.948693    7876.07   \n",
      "4         19000        -602112   4.698869       1291   4.663873    6021.06   \n",
      "...         ...            ...        ...        ...        ...        ...   \n",
      "9995      10000       -1928704  12.494690       4180  12.360713   51667.78   \n",
      "9996      10000       -2158592  13.844609       4663  13.729719   64021.68   \n",
      "9997      10000        -124416   3.568144        302   3.251291     981.89   \n",
      "9998      10000        -162304   6.892377        413   6.689346    2762.70   \n",
      "9999      10000       -4785152   7.916714       9668   7.923616   76605.52   \n",
      "\n",
      "      inpkt_num_frac_total  inpkt_avg_ordering  inpkt_std_ordering  \\\n",
      "0                 0.068421          704.106154          398.486335   \n",
      "1                 0.023053          264.406393          150.591146   \n",
      "2                 0.065263          668.259677          381.878642   \n",
      "3                 0.069684          713.503021          406.205288   \n",
      "4                 0.067947          694.740511          395.028889   \n",
      "...                    ...                 ...                 ...   \n",
      "9995              0.418000         2270.961722         1337.407077   \n",
      "9996              0.466300         2505.849024         1450.994832   \n",
      "9997              0.030200          180.175497          101.241755   \n",
      "9998              0.041300          241.169492          138.848134   \n",
      "9999              0.966800         5006.719797         2876.437267   \n",
      "\n",
      "      inpkt_num_frac_outpkt  inpkt_sum_firstn  outpkt_num  outpkt_avg  \\\n",
      "0                 10.743802             16.10         121    4.570661   \n",
      "1                  5.475000             27.52          80    4.275500   \n",
      "2                 10.508475             28.09         118    5.799153   \n",
      "3                 10.852459             25.24         122    6.503607   \n",
      "4                 11.226087             19.71         115    5.091739   \n",
      "...                     ...               ...         ...         ...   \n",
      "9995              10.121065             48.06         413   13.850678   \n",
      "9996              10.431767             75.71         447   15.043110   \n",
      "9997               5.118644             30.53          59    5.190000   \n",
      "9998               4.302083             48.14          96    7.765833   \n",
      "9999              30.024845             78.31         322    7.709472   \n",
      "\n",
      "      outpkt_sum  outpkt_num_frac_total  outpkt_avg_ordering  \\\n",
      "0        5579.63               0.006368           773.322314   \n",
      "1        2046.88               0.004211           226.162500   \n",
      "2        6769.72               0.006211           786.110169   \n",
      "3        7876.07               0.006421           820.139344   \n",
      "4        6021.06               0.006053           789.608696   \n",
      "...          ...                    ...                  ...   \n",
      "9995    51667.78               0.041300          2549.414044   \n",
      "9996    64021.68               0.044700          3062.015660   \n",
      "9997      981.89               0.005900           179.101695   \n",
      "9998     2762.70               0.009600           309.197917   \n",
      "9999    76605.52               0.032200          4627.602484   \n",
      "\n",
      "      outpkt_std_ordering  outpkt_num_frac_inpkt  outpkt_sum_firstn  \n",
      "0              515.483953               0.093077               7.39  \n",
      "1              139.231951               0.182648               9.71  \n",
      "2              472.735508               0.095161               7.83  \n",
      "3              513.916038               0.092145              11.53  \n",
      "4              503.993490               0.089078               7.17  \n",
      "...                   ...                    ...                ...  \n",
      "9995          1173.380403               0.098804              17.30  \n",
      "9996          1621.869237               0.095861              42.56  \n",
      "9997           118.245320               0.195364              17.90  \n",
      "9998           166.667122               0.232446              20.69  \n",
      "9999          3076.060409               0.033306              30.42  \n",
      "\n",
      "[29000 rows x 19 columns]>\n",
      "Target Vector Shape (y): (29000,)\n"
     ]
    }
   ],
   "source": [
    "mon_features['label'] = mon_labels.values\n",
    "unmon_features['label'] = -1\n",
    "\n",
    "combined_data = pd.concat([mon_features, unmon_features], axis=0)\n",
    "combined_data.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "X = combined_data.drop('label', axis=1)\n",
    "y = combined_data['label']\n",
    "\n",
    "print(\"Combined Data Shape:\", combined_data.shape)\n",
    "print(\"Feature Matrix Shape (X):\", X.shape)\n",
    "print(X.head)\n",
    "print(\"Target Vector Shape (y):\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hphvNPGUKNgK",
    "outputId": "7505097e-881c-4050-f9d9-20626509d482"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23200, 19) (5800, 19)\n",
      "Accuracy: 0.7636206896551724\n",
      "Precision 0.7636206896551724\n",
      "Recall 0.6462482983847709\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.98      1.00      0.99      1977\n",
      "           0       0.33      0.37      0.35        35\n",
      "           1       0.65      0.53      0.58        38\n",
      "           2       0.60      0.78      0.68        37\n",
      "           3       0.55      0.58      0.57        36\n",
      "           4       0.59      0.76      0.67        34\n",
      "           5       0.66      0.64      0.65        36\n",
      "           6       0.55      0.86      0.67        35\n",
      "           7       0.73      0.64      0.68        47\n",
      "           8       0.79      0.59      0.68        39\n",
      "           9       0.49      0.69      0.57        32\n",
      "          10       0.50      0.55      0.52        33\n",
      "          11       0.58      0.71      0.64        45\n",
      "          12       0.79      0.86      0.82        43\n",
      "          13       0.36      0.35      0.35        40\n",
      "          14       0.59      0.52      0.55        44\n",
      "          15       0.55      0.73      0.63        37\n",
      "          16       0.57      0.68      0.62        40\n",
      "          17       0.62      0.67      0.64        42\n",
      "          18       0.80      0.90      0.85        40\n",
      "          19       0.54      0.62      0.58        32\n",
      "          20       0.86      0.98      0.91        44\n",
      "          21       0.64      0.57      0.61        40\n",
      "          22       0.51      0.55      0.53        38\n",
      "          23       0.77      0.63      0.70        38\n",
      "          24       0.38      0.34      0.36        38\n",
      "          25       0.56      0.49      0.52        39\n",
      "          26       0.63      0.69      0.66        42\n",
      "          27       0.83      0.67      0.74        45\n",
      "          28       0.78      0.78      0.78        41\n",
      "          29       0.56      0.61      0.58        31\n",
      "          30       0.55      0.61      0.58        36\n",
      "          31       0.72      0.67      0.69        42\n",
      "          32       0.44      0.40      0.42        42\n",
      "          33       0.60      0.66      0.63        44\n",
      "          34       0.59      0.46      0.52        37\n",
      "          35       0.89      0.69      0.77        35\n",
      "          36       0.57      0.76      0.65        33\n",
      "          37       0.61      0.49      0.54        45\n",
      "          38       0.61      0.62      0.62        45\n",
      "          39       0.70      0.70      0.70        40\n",
      "          40       0.57      0.51      0.54        51\n",
      "          41       0.69      0.70      0.70        44\n",
      "          42       0.39      0.32      0.35        37\n",
      "          43       0.86      0.71      0.78        35\n",
      "          44       0.97      0.95      0.96        40\n",
      "          45       0.44      0.49      0.46        47\n",
      "          46       0.62      0.56      0.59        41\n",
      "          47       0.73      0.60      0.66        40\n",
      "          48       0.80      0.57      0.67        42\n",
      "          49       0.74      0.74      0.74        42\n",
      "          50       0.68      0.67      0.67        42\n",
      "          51       0.62      0.52      0.57        50\n",
      "          52       0.57      0.79      0.66        43\n",
      "          53       0.52      0.73      0.61        30\n",
      "          54       0.78      0.66      0.71        47\n",
      "          55       0.50      0.56      0.53        39\n",
      "          56       0.97      0.90      0.94        40\n",
      "          57       0.74      0.42      0.54        33\n",
      "          58       0.69      0.81      0.74        43\n",
      "          59       0.90      0.84      0.87        44\n",
      "          60       0.76      0.82      0.79        45\n",
      "          61       0.64      0.54      0.59        46\n",
      "          62       0.67      0.61      0.64        49\n",
      "          63       0.60      0.60      0.60        43\n",
      "          64       0.65      0.71      0.68        31\n",
      "          65       0.64      0.59      0.61        51\n",
      "          66       0.69      0.78      0.74        32\n",
      "          67       0.71      0.80      0.75        45\n",
      "          68       0.90      0.49      0.63        37\n",
      "          69       0.73      0.75      0.74        36\n",
      "          70       0.88      0.93      0.90        40\n",
      "          71       0.57      0.62      0.60        37\n",
      "          72       0.61      0.46      0.52        48\n",
      "          73       0.69      0.76      0.72        46\n",
      "          74       0.57      0.44      0.50        52\n",
      "          75       0.74      0.80      0.77        40\n",
      "          76       0.80      0.92      0.86        36\n",
      "          77       0.57      0.40      0.47        50\n",
      "          78       0.57      0.37      0.45        43\n",
      "          79       0.54      0.50      0.52        44\n",
      "          80       0.72      0.79      0.75        42\n",
      "          81       0.47      0.50      0.49        34\n",
      "          82       0.67      0.60      0.63        43\n",
      "          83       0.64      0.57      0.60        37\n",
      "          84       0.58      0.61      0.59        36\n",
      "          85       0.80      0.84      0.82        43\n",
      "          86       0.87      0.92      0.89        37\n",
      "          87       0.76      0.74      0.75        39\n",
      "          88       0.65      0.55      0.59        40\n",
      "          89       0.43      0.46      0.44        35\n",
      "          90       0.81      0.74      0.78        35\n",
      "          91       0.53      0.56      0.55        32\n",
      "          92       0.53      0.43      0.47        42\n",
      "          93       0.93      0.80      0.86        51\n",
      "          94       0.45      0.56      0.50        36\n",
      "\n",
      "    accuracy                           0.76      5800\n",
      "   macro avg       0.65      0.65      0.64      5800\n",
      "weighted avg       0.77      0.76      0.76      5800\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1977    0    0 ...    0    0    0]\n",
      " [   2   13    0 ...    0    0    2]\n",
      " [   0    0   20 ...    0    0    0]\n",
      " ...\n",
      " [   2    0    0 ...   18    0    1]\n",
      " [   0    1    0 ...    0   41    0]\n",
      " [   0    1    0 ...    1    0   20]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix ,precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV , cross_val_score\n",
    "\n",
    "\n",
    "# 1. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# 2. 데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 3. SVM 모델 학습\n",
    "svm_model = SVC(kernel='rbf', C=200, gamma=0.3)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# 4. 예측 및 평가\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision\", precision_score(y_test, y_pred, average='micro'))\n",
    "print(\"Recall\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# param_grid = {'C': [0.1, 1, 10],\n",
    "#               'gamma': [1, 0.1],\n",
    "#               'kernel': ['rbf', 'sigmoid']}\n",
    "\n",
    "# grid = GridSearchCV(SVC(), param_grid, cv=5, n_jobs=-1)\n",
    "# grid.fit(X_train, y_train)\n",
    "\n",
    "# print(f\"Grid Search 최적 파라미터: {grid.best_params_}\")\n",
    "# print(f\"Grid Search 최적 모델: {grid.best_estimator_}\")\n",
    "\n",
    "\n",
    "# best_model = grid.best_estimator_\n",
    "# best_model.fit(X_train, y_train)\n",
    "# best_pred = best_model.predict(X_test)\n",
    "\n",
    "# print(\"accuracy on test dataset(best parameters):  {:.2f}%\".format(accuracy_score(y_test, best_pred) * 100))\n",
    "\n",
    "# scores = cross_val_score(best_model, X_test, y_test, cv=3, n_jobs=-1)\n",
    "# print('cross-val-score(best model): {}'.format([score * 100 for score in scores]))\n",
    "# print('cross-val-score.mean(best model): {:.2f}%'.format(scores.mean() * 100))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
